{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a777d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import random\n",
    "import copy\n",
    "import packages.baseline_model as baselibe_model\n",
    "import packages.common_functions as common_functions\n",
    "from skimage import io\n",
    "import cv2\n",
    "import packages.trans_in_rgb as trans_in_rgb\n",
    "import matplotlib.pyplot as plt\n",
    "import packages.CL_model as CL_model\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from jpeg2dct.numpy import load, loads\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGBProjectionHead(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    projection head for contrastive learning\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(512, bias_initializer=tf.keras.initializers.constant(0.01),\n",
    "                                            kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                                            bias_regularizer=regularizers.l2(1e-4))\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.dense2 = tf.keras.layers.Dense(256, bias_initializer=tf.keras.initializers.constant(0.01),\n",
    "                                            kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                                            bias_regularizer=regularizers.l2(1e-4))\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs[0] + inputs[1]\n",
    "        x = self.dense1(x)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        #x = tf.concat((x,inputs[1]), 1)\n",
    "        output = self.dense2(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b475f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet18_BaseEncoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, layer_params=None, method=\"late_concate\"):\n",
    "        super(Resnet18_BaseEncoder, self).__init__()\n",
    "\n",
    "        self.method = method\n",
    "        if layer_params is None:\n",
    "            layer_params = [2, 2, 2, 2]\n",
    "        self.y_input_bn = tf.keras.layers.BatchNormalization()\n",
    "        self.cbcr_input_bn = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.layer1_y = make_basic_block_layer(filter_num=64,\n",
    "                                             blocks=1, dimen_match=True) # y:56,56,64\n",
    "        self.cb2_y = make_basic_block_layer(filter_num=128,\n",
    "                                             blocks=1, stride=2) # y:28,28,128\n",
    "        self.cb2_cbcr = tf.keras.layers.Conv2D(filters=128,\n",
    "                                               kernel_size=(1,1),\n",
    "                                               strides=1,\n",
    "                                               padding=\"same\")\n",
    "        self.cb_bn = tf.keras.layers.BatchNormalization()\n",
    "        self.layer4 = make_basic_block_layer(filter_num=512,\n",
    "                                             blocks=2, # 14,14,512\n",
    "                                             stride=2)\n",
    "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        y = self.y_input_bn(inputs[0], training=training)\n",
    "        cb_cr = self.cbcr_input_bn(inputs[1], training=training)\n",
    "\n",
    "        y = self.layer1_y(y, training=training) # 56,56,64\n",
    "        y = self.cb2_y(y, training=training) # 28,28,128\n",
    "        cb_cr = tf.nn.relu(self.cb_bn(self.cb2_cbcr(cb_cr), training=training)) #28,28,128\n",
    "        x = tf.concat((y, cb_cr), axis=3) #28,28,256\n",
    "        x = self.layer4(x, training=training) #14,14,512\n",
    "        x = self.avgpool(x)\n",
    "        output = self.flatten(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "def make_basic_block_layer(filter_num, blocks, k_size=(3,3), stride=1, dimen_match=False):\n",
    "    res_block = tf.keras.Sequential()\n",
    "    res_block.add(BasicBlock(filter_num, k_size=k_size, stride=stride, dimen_match=dimen_match))\n",
    "\n",
    "    for _ in range(1, blocks):\n",
    "        res_block.add(BasicBlock(filter_num, stride=1))\n",
    "\n",
    "    return res_block\n",
    "\n",
    "\n",
    "class BasicBlock(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, filter_num, k_size=(3,3), stride=1, dimen_match=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=k_size,\n",
    "                                            strides=stride,\n",
    "                                            padding=\"same\")\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                            kernel_size=k_size,\n",
    "                                            strides=1,\n",
    "                                            padding=\"same\")\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        if stride != 1 or dimen_match is True:\n",
    "            self.downsample = tf.keras.Sequential()\n",
    "            self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                                       kernel_size=(1, 1),\n",
    "                                                       strides=stride))\n",
    "            self.downsample.add(tf.keras.layers.BatchNormalization())\n",
    "        else:\n",
    "            self.downsample = lambda x: x\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        residual = self.downsample(inputs)\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "\n",
    "        output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616242a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyper parameters\n",
    "batch_size = 128\n",
    "tau = 0.1\n",
    "weights_array = np.ones((batch_size,), dtype=np.float32)\n",
    "\n",
    "# Define base encoder and projection head\n",
    "feature_extractor = Resnet18_BaseEncoder()\n",
    "projection_head = RGBProjectionHead()\n",
    "\n",
    "pic_num_list = [3000, 2993, 3000, 3000, 3000, 3000, 3000, 2999, 3000, 3000, 2999, 3000, 3000, 2994, 3000]\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "\n",
    "# define batch for query and positive\n",
    "query_batch_y = np.zeros((batch_size, 28, 28, 6))\n",
    "query_batch_cbcr = np.zeros((batch_size, 14, 14, 6))\n",
    "positive_batch_y = np.zeros((batch_size, 28, 28, 6))\n",
    "positive_batch_cbcr = np.zeros((batch_size, 14, 14, 6))\n",
    "\n",
    "error_list = []\n",
    "\n",
    "subject_num = 10\n",
    "error_list = np.zeros((subject_num,1))\n",
    "error_list = error_list.tolist()\n",
    "\n",
    "identity_representations_list = []\n",
    "for sub in range(subject_num):\n",
    "    identity_representation = tf.Variable(tf.zeros((1, 512)), trainable=True)\n",
    "    identity_representations_list.append(identity_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ddb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(5000)):\n",
    "\n",
    "    subject_index = np.random.choice(subject_num, subject_num, replace=False)\n",
    "    for sub in subject_index:\n",
    "        \n",
    "        left_landmarks = np.load(\n",
    "            \"/home/walter/MPIIFaceGaze_png/\" + str(sub) + \"/left_landmarks.npy\")\n",
    "        right_landmarks = np.load(\n",
    "            \"/home/walter/MPIIFaceGaze_png/\" + str(sub) + \"/right_landmarks.npy\")\n",
    "        \n",
    "        index = np.random.choice(pic_num_list[sub], batch_size, replace=False)\n",
    "        j = 0\n",
    "        \n",
    "        for i in index:\n",
    "            jpeg_file = '/home/walter/MPIIFaceGaze_png/' + str(sub) + '/' + str(i) + '.png'\n",
    "            img = io.imread(jpeg_file) / 255.\n",
    "\n",
    "            noised_image1, angle_1 = trans_in_rgb.data_transformation(copy.deepcopy(img), left_landmarks[i], right_landmarks[i])\n",
    "            noised_image2, angle_2 = trans_in_rgb.data_transformation(copy.deepcopy(img), left_landmarks[i], right_landmarks[i])\n",
    "            \n",
    "            #weights_array[j] = (6 - np.abs(angle_1 - angle_2) / 10.)/4\n",
    "            weights_array[j] = (3 - np.abs(angle_1 - angle_2) / 10.)/2\n",
    "            #weights_array[j] = (2 - np.abs(angle_1 - angle_2) / 10.)/1.25\n",
    "\n",
    "            noised_image1 = cv2.resize(noised_image1, (224, 224))\n",
    "            noised_image2 = cv2.resize(noised_image2, (224, 224))\n",
    "\n",
    "            noised_image1 *= 255\n",
    "            noised_image1 = np.round(noised_image1).astype(np.uint8)\n",
    "            noised_image2 *= 255\n",
    "            noised_image2 = np.round(noised_image2).astype(np.uint8)\n",
    "            io.imsave(\"/home/walter/CVPR23/MPIIFaceGaze/temp_pic/noised_image1.jpg\", noised_image1)\n",
    "            io.imsave(\"/home/walter/CVPR23/MPIIFaceGaze/temp_pic/noised_image2.jpg\", noised_image2)\n",
    "\n",
    "            jpeg_noised = \"/home/walter/CVPR23/MPIIFaceGaze/temp_pic/noised_image1.jpg\"\n",
    "            dct_y, dct_cb, dct_cr = load(jpeg_noised)\n",
    "            # channel selection\n",
    "            dct_y = np.concatenate((np.concatenate((dct_y[:, :, 0:3], dct_y[:, :, 8:10]), axis=2),\n",
    "                                    np.reshape(dct_y[:, :, 16], (28, 28, 1))), axis=2)\n",
    "\n",
    "            dct_cb = np.concatenate((dct_cb[:, :, 0:2], np.reshape(dct_cb[:, :, 8], (14, 14, 1))), axis=2)\n",
    "            dct_cr = np.concatenate((dct_cr[:, :, 0:2], np.reshape(dct_cr[:, :, 8], (14, 14, 1))), axis=2)\n",
    "            cb_cr = np.concatenate([dct_cb, dct_cr], 2)\n",
    "            query_batch_y[j, :, :, :] = dct_y\n",
    "            query_batch_cbcr[j, :, :, :] = cb_cr\n",
    "\n",
    "            jpeg_noised = \"/home/walter/CVPR23/MPIIFaceGaze/temp_pic/noised_image2.jpg\"\n",
    "            dct_y, dct_cb, dct_cr = load(jpeg_noised)\n",
    "            # channel selection\n",
    "            dct_y = np.concatenate((np.concatenate((dct_y[:, :, 0:3], dct_y[:, :, 8:10]), axis=2),\n",
    "                                    np.reshape(dct_y[:, :, 16], (28, 28, 1))), axis=2)\n",
    "\n",
    "            dct_cb = np.concatenate((dct_cb[:, :, 0:2], np.reshape(dct_cb[:, :, 8], (14, 14, 1))), axis=2)\n",
    "            dct_cr = np.concatenate((dct_cr[:, :, 0:2], np.reshape(dct_cr[:, :, 8], (14, 14, 1))), axis=2)\n",
    "            cb_cr = np.concatenate([dct_cb, dct_cr], 2)\n",
    "            positive_batch_y[j, :, :, :] = dct_y\n",
    "            positive_batch_cbcr[j, :, :, :] = cb_cr\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            x1_feature = tf.math.l2_normalize(\n",
    "                projection_head([feature_extractor([query_batch_y, query_batch_cbcr], training=True), tf.tile(identity_representations_list[sub], [batch_size, 1])], training=True),axis=1)\n",
    "            \n",
    "            x2_feature = tf.math.l2_normalize(\n",
    "                projection_head([feature_extractor([positive_batch_y, positive_batch_cbcr], training=True), tf.tile(identity_representations_list[sub], [batch_size, 1])], training=True),axis=1)\n",
    "\n",
    "            x1_x2_mat = tf.exp(tf.matmul(x1_feature, tf.transpose(x2_feature)) / tau)\n",
    "\n",
    "            denominator = tf.reduce_sum(x1_x2_mat, 1)\n",
    "            # positive_sim = tf.linalg.diag_part(x1_x2_mat)\n",
    "            prob = x1_x2_mat / tf.reshape(denominator, (x1_feature.shape[0], 1))\n",
    "            prob = tf.linalg.diag_part(prob)\n",
    "            weighted_prob = prob * weights_array\n",
    "\n",
    "            loss = -tf.reduce_mean(tf.math.log(weighted_prob))\n",
    "\n",
    "        grads = tape.gradient(loss, feature_extractor.trainable_variables + projection_head.trainable_variables+[identity_representations_list[sub]])\n",
    "        optimizer.apply_gradients(\n",
    "            grads_and_vars=zip(grads, feature_extractor.trainable_variables + projection_head.trainable_variables+[identity_representations_list[sub]]))\n",
    "        error_list[sub].append(loss.numpy())\n",
    "\n",
    "    print(\"current epoch: \", epoch, \"current loss\", loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77cc323",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list_arr= np.array(error_list)\n",
    "for sub_fig in range(subject_num):\n",
    "    plt.plot(error_list_arr[sub_fig][1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d6cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor.save_weights(\"/home/walter/CVPR23/MPIIFaceGaze/TOSN_rotation_multitask/base_1\")\n",
    "# projection_head.save_weights(\"/home/walter/CVPR23/MPIIFaceGaze/TOSN_rotation_multitask/pro_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f4afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dct_coefficients_batch(local_index, subject_name):\n",
    "    \n",
    "    j = 0\n",
    "    local_mini_batch_y = np.zeros((local_index.shape[0], 56, 56, 6))\n",
    "    local_mini_batch_cbcr = np.zeros((local_index.shape[0], 28, 28, 6))\n",
    "    for i in local_index:\n",
    "        jpeg_file = '/home/walter/MPIIFaceGaze_normalized/' + subject_name + '/' + str(i) + '.jpg'\n",
    "        dct_y, dct_cb, dct_cr = load(jpeg_file)\n",
    "        # channel selection\n",
    "        dct_y = np.concatenate((np.concatenate((dct_y[:, :, 0:3], dct_y[:, :, 8:10]), axis=2),\n",
    "                                np.reshape(dct_y[:, :, 16], (56, 56, 1))), axis=2)\n",
    "\n",
    "        dct_cb = np.concatenate((dct_cb[:, :, 0:2], np.reshape(dct_cb[:, :, 8], (28, 28, 1))), axis=2)\n",
    "        dct_cr = np.concatenate((dct_cr[:, :, 0:2], np.reshape(dct_cr[:, :, 8], (28, 28, 1))), axis=2)\n",
    "        cb_cr = np.concatenate([dct_cb, dct_cr], 2)\n",
    "        #cb_cr = np.repeat(np.repeat(cb_cr, 2, 0), 2, 1)\n",
    "        #img = cv2.resize(img, (224,224))\n",
    "        local_mini_batch_y[j, :, :, :] = dct_y\n",
    "        local_mini_batch_cbcr[j, :, :, :] = cb_cr\n",
    "        j += 1\n",
    "    return local_mini_batch_y, local_mini_batch_cbcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053ad4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dct_coefficients_batch_224(local_index, subject_name):\n",
    "    \n",
    "    j = 0\n",
    "    local_mini_batch_y = np.zeros((local_index.shape[0], 28, 28, 6))\n",
    "    local_mini_batch_cbcr = np.zeros((local_index.shape[0], 14, 14, 6))\n",
    "    for i in local_index:\n",
    "        jpeg_file = '/home/walter/MPIIFaceGaze_normalized/' + subject_name + '/' + str(i) + '.jpg'\n",
    "        img = io.imread(jpeg_file)\n",
    "        resized_image = cv2.resize(img, (224, 224))\n",
    "        io.imsave(\"/home/walter/CVPR23/MPIIFaceGaze/temp_pic/resized_image.jpg\", resized_image)\n",
    "\n",
    "        jpeg_file = \"/home/walter/CVPR23/MPIIFaceGaze/temp_pic/resized_image.jpg\"\n",
    "\n",
    "        dct_y, dct_cb, dct_cr = load(jpeg_file)\n",
    "        # channel selection\n",
    "        dct_y = np.concatenate((np.concatenate((dct_y[:, :, 0:3], dct_y[:, :, 8:10]), axis=2),\n",
    "                                np.reshape(dct_y[:, :, 16], (28, 28, 1))), axis=2)\n",
    "\n",
    "        dct_cb = np.concatenate((dct_cb[:, :, 0:2], np.reshape(dct_cb[:, :, 8], (14, 14, 1))), axis=2)\n",
    "        dct_cr = np.concatenate((dct_cr[:, :, 0:2], np.reshape(dct_cr[:, :, 8], (14, 14, 1))), axis=2)\n",
    "        cb_cr = np.concatenate([dct_cb, dct_cr], 2)\n",
    "        #cb_cr = np.repeat(np.repeat(cb_cr, 2, 0), 2, 1)\n",
    "        #img = cv2.resize(img, (224,224))\n",
    "        local_mini_batch_y[j, :, :, :] = dct_y\n",
    "        local_mini_batch_cbcr[j, :, :, :] = cb_cr\n",
    "        j += 1\n",
    "    return local_mini_batch_y, local_mini_batch_cbcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a1c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(subject_name):\n",
    "    \n",
    "    min_val = 100.\n",
    "    for epoch in tqdm(range(500)):\n",
    "        # optimization\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = GazeEstimation(feature_extractor([train_mini_batch_y, train_mini_batch_cbcr]))\n",
    "            loss = tf.reduce_mean(tf.square(labels_per[train_index] - prediction))\n",
    "\n",
    "        grads = tape.gradient(loss, GazeEstimation.trainable_variables + feature_extractor.trainable_variables)\n",
    "        optimizer_per.apply_gradients(grads_and_vars=zip(grads, GazeEstimation.trainable_variables + feature_extractor.trainable_variables))\n",
    "\n",
    "        # training error\n",
    "\n",
    "        train_angle_error = common_functions.avg_angle_error(prediction, labels_per[train_index])\n",
    "        train_error_per.append(train_angle_error.numpy())\n",
    "\n",
    "        # validation error\n",
    "\n",
    "        prediction = GazeEstimation(feature_extractor([val_mini_batch_y, val_mini_batch_cbcr]))\n",
    "        validation_angle_error = common_functions.avg_angle_error(prediction, labels_per[val_index])\n",
    "\n",
    "        val_error_per.append(validation_angle_error.numpy())\n",
    "        if validation_angle_error < min_val:\n",
    "            min_val = validation_angle_error\n",
    "            feature_extractor.save_weights('/home/walter/CL_gaze_project/MPIIFaceGaze/experimental_model/' + subject_name + '/dct_ours/base')\n",
    "            GazeEstimation.save_weights('/home/walter/CL_gaze_project/MPIIFaceGaze/experimental_model/' + subject_name + '/dct_ours/gaze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3353b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(subject_name):\n",
    "    \n",
    "    feature_extractor.load_weights('/home/walter/CL_gaze_project/MPIIFaceGaze/experimental_model/' + subject_name + '/dct_ours/base')\n",
    "    GazeEstimation.load_weights('/home/walter/CL_gaze_project/MPIIFaceGaze/experimental_model/' + subject_name + '/dct_ours/gaze')\n",
    "    test_error = 0.\n",
    "    for batch_i in range(batch_number):\n",
    "        start = batch_i * 100\n",
    "        end = (batch_i + 1) * 100\n",
    "        if end >= test_index.shape[0]:\n",
    "            end = test_index.shape[0]\n",
    "        test_batch_y = np.zeros((test_index[start: end].shape[0], 56, 56, 6))\n",
    "        test_batch_cbcr = np.zeros((test_index[start: end].shape[0], 28, 28, 6))\n",
    "        j = 0\n",
    "        for i in test_index[start: end]:\n",
    "            jpeg_file = '/home/walter/MPIIFaceGaze_normalized/' + subject_name + '/' + str(i) + '.jpg'\n",
    "            dct_y, dct_cb, dct_cr = load(jpeg_file)\n",
    "            # channel selection\n",
    "            dct_y = np.concatenate((np.concatenate((dct_y[:, :, 0:3], dct_y[:, :, 8:10]), axis=2),\n",
    "                                    np.reshape(dct_y[:, :, 16], (56, 56, 1))), axis=2)\n",
    "\n",
    "            dct_cb = np.concatenate((dct_cb[:, :, 0:2], np.reshape(dct_cb[:, :, 8], (28, 28, 1))), axis=2)\n",
    "            dct_cr = np.concatenate((dct_cr[:, :, 0:2], np.reshape(dct_cr[:, :, 8], (28, 28, 1))), axis=2)\n",
    "            cb_cr = np.concatenate([dct_cb, dct_cr], 2)\n",
    "\n",
    "            test_batch_y[j, :, :, :] = dct_y\n",
    "            test_batch_cbcr[j, :, :, :] = cb_cr\n",
    "            j += 1\n",
    "        prediction = GazeEstimation(feature_extractor([test_batch_y, test_batch_cbcr]))\n",
    "        test_error += common_functions.avg_angle_error(prediction, labels_per[test_index[start: end]]) \\\n",
    "                      * test_index[start: end].shape[0]\n",
    "    return test_error.numpy() / test_index.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7905cfdc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "per_size = 100\n",
    "print(\"current size for personalization is\", per_size-25)\n",
    "name_list = ['p10', 'p11', 'p12', 'p13', 'p14']\n",
    "#name_list = ['p14']\n",
    "avg_list = []\n",
    "for name in name_list:\n",
    "    \n",
    "    avg_error_list = []\n",
    "    labels_per = np.load(\"/home/walter/MPIIFaceGaze_normalized/\" + name + \"/labels.npy\")\n",
    "    data_size = labels_per.shape[0]\n",
    "    eposide = 6\n",
    "    print(name, \" start to train.\")\n",
    "    total_index = np.load(\"/home/walter/MPIIFaceGaze_normalized/\" + name + \"/random_index.npy\")\n",
    "\n",
    "    for i in range(eposide):\n",
    "        feature_extractor.load_weights(\"/home/walter/CVPR23/MPIIFaceGaze/TOSN_rotation_multitask/base_1\")\n",
    "        GazeEstimation = CL_model.GazeEstimationHead()\n",
    "\n",
    "        optimizer_per = tf.keras.optimizers.Adam(learning_rate=.001)\n",
    "\n",
    "        train_error_per = []\n",
    "        val_error_per = []\n",
    "\n",
    "        train_start = int(per_size*i)\n",
    "        train_end = train_start + per_size - 25\n",
    "\n",
    "        train_index = total_index[train_start: train_end]\n",
    "        val_index = total_index[train_end: train_end + 25]\n",
    "\n",
    "        # read training data\n",
    "        train_mini_batch_y, train_mini_batch_cbcr = read_dct_coefficients_batch(train_index, name)\n",
    "        val_mini_batch_y, val_mini_batch_cbcr = read_dct_coefficients_batch(val_index, name)\n",
    "\n",
    "        if i == 0:\n",
    "            test_index =  total_index[train_end + 25: data_size]\n",
    "        else:\n",
    "            test_index =  np.concatenate((total_index[0: train_start], total_index[train_end + 25: data_size]), 0)\n",
    "\n",
    "\n",
    "        if test_index.shape[0] % 100 != 0:\n",
    "            batch_number = int(test_index.shape[0]/100) + 1\n",
    "        else:\n",
    "            batch_number = int(test_index.shape[0]/100)\n",
    "\n",
    "        print(\" current eposide: \", i+1, \" start to train from \", train_start, \"to \", train_end, \n",
    "              \"train samples:\", train_index.shape[0], \"val samples:\", val_index.shape[0], \"test samples:\", test_index.shape[0])\n",
    "        train(name)\n",
    "        test_error = test(name)\n",
    "        avg_error_list.append(test_error)\n",
    "        val_error_per = np.array(val_error_per)\n",
    "        plt.ylim(2,7)\n",
    "\n",
    "        plt.plot(val_error_per,label='val')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        min_val_index = np.argmin(val_error_per)\n",
    "        print(name, \":\", train_start, \"to \", train_end, \" achieve best accuarcy \", test_error,\" at the \", min_val_index, \"th iteration\")\n",
    "        print(\" \")\n",
    "        print(\" \")\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "    print(name, \"average angular error over six trails\", np.mean(np.array(avg_error_list)))\n",
    "    avg_list.append(np.mean(np.array(avg_error_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9467785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
